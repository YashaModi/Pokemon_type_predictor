{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "This notebook trains the XGBoost (Baseline) and MLP (Hybrid) models used for Pokemon Type Prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "from pokemon_predictor import config\n",
    "from pokemon_predictor.tabular import load_data\n",
    "from pokemon_predictor.losses import FocalLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgboost():\n",
    "    print(\"Training XGBoost Model...\")\n",
    "    X_train, X_test, y_train, y_test, classes = load_data('rgb', split_data=True)\n",
    "    \n",
    "    mlb = MultiLabelBinarizer()\n",
    "    mlb.classes_ = classes\n",
    "    \n",
    "    model = MultiOutputClassifier(XGBClassifier(n_estimators=100, max_depth=5, learning_rate=0.1, colsample_bytree=0.75, n_jobs=-1, random_state=42))\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    score = model.score(X_test, y_test)\n",
    "    print(f\"XGBoost Test Accuracy (Subset): {score:.4f}\")\n",
    "    \n",
    "    out_path = config.MODELS_DIR / \"xgboost_model.pkl\"\n",
    "    joblib.dump(model, out_path)\n",
    "    print(f\"Saved XGBoost model to {out_path}\")\n",
    "    \n",
    "    y_labels = pd.read_csv(config.PROCESSED_DATA_DIR / \"y_labels.csv\")\n",
    "    y_list = []\n",
    "    for _, row in y_labels.iterrows():\n",
    "        types = [row['type1']]\n",
    "        if pd.notna(row['type2']):\n",
    "            types.append(row['type2'])\n",
    "        y_list.append(types)\n",
    "    mlb_full = MultiLabelBinarizer()\n",
    "    mlb_full.fit(y_list)\n",
    "    joblib.dump(mlb_full, config.MODELS_DIR / \"mlb.pkl\")\n",
    "    print(f\"Saved MLB to {config.MODELS_DIR / 'mlb.pkl'}\")\n",
    "\n",
    "train_xgboost()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mlp():\n",
    "    print(\"\\nTraining MLP Model (Hybrid)...\")\n",
    "    X_train, X_test, y_train, y_test, classes = load_data('hybrid', split_data=True)\n",
    "    \n",
    "    model = Sequential([\n",
    "        Input(shape=(X_train.shape[1],)),\n",
    "        Dense(512, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.4),\n",
    "        Dense(256, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        Dense(len(classes), activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer=Adam(0.001), loss=FocalLoss(), metrics=['accuracy', 'binary_accuracy'])\n",
    "    \n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_test, y_test),\n",
    "        epochs=50,\n",
    "        batch_size=32,\n",
    "        callbacks=[early_stop],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    out_path = config.MODELS_DIR / \"mlp_model_optimized.h5\"\n",
    "    model.save(out_path)\n",
    "    print(f\"Saved MLP model to {out_path}\")\n",
    "    \n",
    "    print(\"Finding best threshold...\")\n",
    "    y_pred = model.predict(X_test)\n",
    "    best_thresh = 0.5\n",
    "    best_f1 = 0.0\n",
    "    \n",
    "    from sklearn.metrics import f1_score\n",
    "    for thresh in np.arange(0.1, 0.9, 0.05):\n",
    "        y_pred_bin = (y_pred > thresh).astype(int)\n",
    "        f1 = f1_score(y_test, y_pred_bin, average='micro')\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_thresh = thresh\n",
    "            \n",
    "    print(f\"Best Threshold: {best_thresh:.2f} (F1: {best_f1:.4f})\")\n",
    "    joblib.dump(best_thresh, config.MODELS_DIR / \"best_threshold.pkl\")\n",
    "\n",
    "train_mlp()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
