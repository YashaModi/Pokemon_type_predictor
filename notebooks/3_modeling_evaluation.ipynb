{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 3. Modeling and Evaluation\n",
                "\n",
                "This notebook trains and compares two models:\n",
                "1. **XGBoost:** Using K-Means features.\n",
                "2. **MLP (Neural Network):** Using Histogram features."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import os\n",
                "\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import MultiLabelBinarizer\n",
                "from sklearn.multioutput import MultiOutputClassifier\n",
                "from sklearn.metrics import accuracy_score, f1_score, hamming_loss, classification_report\n",
                "\n",
                "from xgboost import XGBClassifier\n",
                "\n",
                "import tensorflow as tf\n",
                "from tensorflow.keras.models import Sequential\n",
                "from tensorflow.keras.layers import Dense, Dropout\n",
                "from tensorflow.keras.optimizers import Adam\n",
                "\n",
                "# Constants\n",
                "DATA_DIR = \"../data/processed\"\n",
                "SEED = 42"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load Data\n",
                "X_kmeans = pd.read_csv(os.path.join(DATA_DIR, \"X_kmeans.csv\"))\n",
                "X_hist = pd.read_csv(os.path.join(DATA_DIR, \"X_hist.csv\"))\n",
                "y_labels = pd.read_csv(os.path.join(DATA_DIR, \"y_labels.csv\"))\n",
                "\n",
                "# Preprocess Labels (Multi-label Binarization)\n",
                "# Some Pokemon have 1 type, some have 2. We need to combine them into a list.\n",
                "y_list = []\n",
                "for _, row in y_labels.iterrows():\n",
                "    types = [row['type1']]\n",
                "    if pd.notna(row['type2']):\n",
                "        types.append(row['type2'])\n",
                "    y_list.append(types)\n",
                "\n",
                "mlb = MultiLabelBinarizer()\n",
                "y_encoded = mlb.fit_transform(y_list)\n",
                "print(f\"Classes: {mlb.classes_}\")\n",
                "print(f\"y shape: {y_encoded.shape}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Split Data\n",
                "# We need to use the same indices for both models to be fair\n",
                "train_idx, test_idx = train_test_split(range(len(y_encoded)), test_size=0.2, random_state=SEED)\n",
                "\n",
                "X_train_xgb = X_kmeans.iloc[train_idx]\n",
                "X_test_xgb = X_kmeans.iloc[test_idx]\n",
                "\n",
                "X_train_mlp = X_hist.iloc[train_idx]\n",
                "X_test_mlp = X_hist.iloc[test_idx]\n",
                "\n",
                "y_train = y_encoded[train_idx]\n",
                "y_test = y_encoded[test_idx]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Model A: XGBoost (K-Means Features)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "xgb_estimator = XGBClassifier(objective='binary:logistic', eval_metric='logloss', use_label_encoder=False)\n",
                "clf_xgb = MultiOutputClassifier(xgb_estimator)\n",
                "\n",
                "print(\"Training XGBoost...\")\n",
                "clf_xgb.fit(X_train_xgb, y_train)\n",
                "y_pred_xgb = clf_xgb.predict(X_test_xgb)\n",
                "\n",
                "print(\"XGBoost Evaluation:\")\n",
                "print(f\"Hamming Loss: {hamming_loss(y_test, y_pred_xgb):.4f}\")\n",
                "print(f\"F1 Score (Macro): {f1_score(y_test, y_pred_xgb, average='macro'):.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Model B: MLP (Histogram Features)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "input_dim = X_train_mlp.shape[1]\n",
                "output_dim = y_encoded.shape[1]\n",
                "\n",
                "model_mlp = Sequential([\n",
                "    Dense(128, activation='relu', input_shape=(input_dim,)),\n",
                "    Dropout(0.3),\n",
                "    Dense(64, activation='relu'),\n",
                "    Dense(output_dim, activation='sigmoid') # Sigmoid for multi-label\n",
                "])\n",
                "\n",
                "model_mlp.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
                "\n",
                "print(\"Training MLP...\")\n",
                "history = model_mlp.fit(X_train_mlp, y_train, epochs=50, batch_size=32, validation_split=0.1, verbose=1)\n",
                "\n",
                "y_pred_probs_mlp = model_mlp.predict(X_test_mlp)\n",
                "y_pred_mlp = (y_pred_probs_mlp > 0.5).astype(int)\n",
                "\n",
                "print(\"MLP Evaluation:\")\n",
                "print(f\"Hamming Loss: {hamming_loss(y_test, y_pred_mlp):.4f}\")\n",
                "print(f\"F1 Score (Macro): {f1_score(y_test, y_pred_mlp, average='macro'):.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Comparison & Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Compare Metrics\n",
                "metrics = {\n",
                "    'Model': ['XGBoost', 'MLP'],\n",
                "    'Hamming Loss': [hamming_loss(y_test, y_pred_xgb), hamming_loss(y_test, y_pred_mlp)],\n",
                "    'F1 Score (Macro)': [f1_score(y_test, y_pred_xgb, average='macro'), f1_score(y_test, y_pred_mlp, average='macro')]\n",
                "}\n",
                "\n",
                "df_res = pd.DataFrame(metrics)\n",
                "print(df_res)\n",
                "\n",
                "df_res.plot(x='Model', kind='bar', subplots=True, layout=(1, 2), figsize=(12, 5))\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Save Models"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pickle\n",
                "import joblib\n",
                "\n",
                "MODEL_DIR = \"../models\"\n",
                "os.makedirs(MODEL_DIR, exist_ok=True)\n",
                "\n",
                "# Save XGB\n",
                "joblib.dump(clf_xgb, os.path.join(MODEL_DIR, \"xgboost_model.pkl\"))\n",
                "\n",
                "# Save MLP\n",
                "model_mlp.save(os.path.join(MODEL_DIR, \"mlp_model.h5\"))\n",
                "\n",
                "# Save Binarizer\n",
                "joblib.dump(mlb, os.path.join(MODEL_DIR, \"mlb.pkl\"))\n",
                "\n",
                "print(\"Models saved.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}