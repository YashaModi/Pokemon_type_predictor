{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1a35def",
   "metadata": {},
   "source": [
    "# Project Notebook\n",
    "Generated from script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5d222b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to sys.path\n",
    "# Assuming notebook is in 'notebooks/' and project root is one level up\n",
    "project_root = Path.cwd().parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))\n",
    "    \n",
    "from pokemon_predictor import config\n",
    "from pokemon_predictor.data_utils import load_data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6665df9d",
   "metadata": {},
   "source": [
    "## 1. Load Data (RGB Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841a04c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load RGB Data for XGBoost\n",
    "X_train_xgb, X_test_xgb, y_train, y_test, classes = load_data('rgb', split_data=True)\n",
    "print(f\"Classes: {classes}\")\n",
    "print(f\"Train Shape: {X_train_xgb.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d65c4c",
   "metadata": {},
   "source": [
    "## 2. Train XGBoost Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5f8a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "xgb = XGBClassifier(eval_metric='logloss', random_state=config.RANDOM_SEED)\n",
    "clf_xgb = MultiOutputClassifier(xgb)\n",
    "clf_xgb.fit(X_train_xgb, y_train)\n",
    "\n",
    "y_pred_xgb = clf_xgb.predict(X_test_xgb)\n",
    "print(f\"XGBoost F1 (Macro): {f1_score(y_test, y_pred_xgb, average='macro'):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34070059",
   "metadata": {},
   "source": [
    "## 3. Train MLP Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7218b114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Histogram Data for MLP\n",
    "X_train_mlp, X_test_mlp, _, _, _ = load_data('hist', split_data=True)\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "input_dim = X_train_mlp.shape[1]\n",
    "output_dim = len(classes)\n",
    "\n",
    "model_mlp = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(input_dim,)),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(output_dim, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_mlp.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model_mlp.fit(X_train_mlp, y_train, epochs=50, batch_size=32, validation_split=0.1, verbose=0)\n",
    "\n",
    "y_pred_probs = model_mlp.predict(X_test_mlp, verbose=0)\n",
    "y_pred_mlp = (y_pred_probs > 0.5).astype(int)\n",
    "print(f\"MLP F1 (Macro): {f1_score(y_test, y_pred_mlp, average='macro'):.4f}\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
